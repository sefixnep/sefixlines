{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28800369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf8b5b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ebfe0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1474d7",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573a7ba",
   "metadata": {},
   "source": [
    "### Only train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ee587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Настройки ---\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "lr = 3e-4\n",
    "models_dir = '../models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Датасет ---\n",
    "train_dataset = Dataset()\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# --- Модель, оптимизатор, лосс ---\n",
    "model = Model().to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "fit_result = {\n",
    "    'train_losses': [],\n",
    "}\n",
    "\n",
    "# --- Обучение ---\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\")\n",
    "    for model_inputs, target in progress_bar:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(model_inputs)\n",
    "        loss = loss_fn(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    fit_result['train_losses'].append(train_loss)\n",
    "    print(f\"Epoch {epoch}: Train loss = {train_loss:.4f}\")\n",
    "\n",
    "# --- Сохранение модели ---\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), f'{models_dir}/model.pt')\n",
    "print(f\"✅ Обучение завершено, модель сохранена в '{models_dir}/model.pt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9037dc1",
   "metadata": {},
   "source": [
    "### Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90723c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Настройки ---\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "lr = 3e-4\n",
    "val_ratio = 0.2\n",
    "models_dir = '../models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Датасеты ---\n",
    "full_dataset = Dataset()\n",
    "all_indices = np.arange(len(full_dataset))\n",
    "train_indices, val_indices = train_test_split(\n",
    "    all_indices,\n",
    "    test_size=val_ratio,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# --- Модель, оптимизатор, лосс ---\n",
    "model = Model().to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "fit_result = {\n",
    "    'train_losses': [],\n",
    "    'val_losses': [],\n",
    "    'val_accuracies': [],\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# --- Обучение ---\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\")\n",
    "    for model_inputs, target in progress_bar:\n",
    "        model_inputs = model_inputs.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(model_inputs)\n",
    "        loss = loss_fn(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    fit_result['train_losses'].append(train_loss)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch} [Val]\")\n",
    "    with torch.no_grad():\n",
    "        for model_inputs, target in val_bar:\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            logits = model(model_inputs)\n",
    "            loss = loss_fn(logits, target)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    fit_result['val_losses'].append(val_loss)\n",
    "    fit_result['val_accuracies'].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(f\"  Train loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val acc:    {val_acc:.4f}\")\n",
    "\n",
    "    # --- Save best model ---\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), f'{models_dir}/best_model.pt')\n",
    "        print(f\"  ✅ New best model saved (val_loss={val_loss:.4f})\")\n",
    "\n",
    "# --- Финальное сохранение ---\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), f'{models_dir}/last_model.pt')\n",
    "print(\"Обучение завершено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19317303",
   "metadata": {},
   "source": [
    "### Folds train & valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# --- Настройки ---\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "lr = 3e-4\n",
    "n_splits = 5\n",
    "models_dir = '../models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Датасет ---\n",
    "full_dataset = Dataset()\n",
    "\n",
    "# --- Подготовка ---\n",
    "best_models = []\n",
    "fit_results = []\n",
    "\n",
    "# --- KFold ---\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset), start=1):\n",
    "    print(f\"\\n===== Fold {fold}/{n_splits} =====\")\n",
    "\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- Модель, оптимизатор, лосс ---\n",
    "    model = Model().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    fit_result = {\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'val_accuracies': [],\n",
    "    }\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    # --- Обучение ---\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # --- Train ---\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Fold {fold} | Epoch {epoch} [Train]\")\n",
    "        for model_inputs, target in progress_bar:\n",
    "            model_inputs = model_inputs.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(model_inputs)\n",
    "            loss = loss_fn(logits, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss = np.mean(train_losses)\n",
    "        fit_result['train_losses'].append(train_loss)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        val_bar = tqdm(val_loader, desc=f\"Fold {fold} | Epoch {epoch} [Val]\")\n",
    "        with torch.no_grad():\n",
    "            for model_inputs, target in val_bar:\n",
    "                model_inputs = model_inputs.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                logits = model(model_inputs)\n",
    "                loss = loss_fn(logits, target)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == target).sum().item()\n",
    "                total += target.size(0)\n",
    "\n",
    "                val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        fit_result['val_losses'].append(val_loss)\n",
    "        fit_result['val_accuracies'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train loss = {train_loss:.4f} | Val loss = {val_loss:.4f} | Val acc = {val_acc:.4f}\")\n",
    "\n",
    "        # --- Save best model per fold ---\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            print(f\"  ✅ New best model for fold {fold} (val_loss={val_loss:.4f})\")\n",
    "\n",
    "    # --- Сохраняем результаты и модель ---\n",
    "    fit_results.append(fit_result)\n",
    "    best_models.append(best_model_state)\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    torch.save(best_model_state, f\"{models_dir}/best_model_fold{fold}.pt\")\n",
    "\n",
    "print(\"\\n✅ Обучение по фолдам завершено.\")\n",
    "print(f\"Всего сохранено лучших моделей: {len(best_models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b29f1",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = Dataset()\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, \n",
    "    drop_last=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for model_inputs in tqdm(test_loader):\n",
    "        model_inputs = model_inputs.to(device=device)\n",
    "        results.append(\n",
    "            model(model_inputs) \\\n",
    "            .cpu().numpy()\n",
    "        )\n",
    "results = np.concatenate(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for fold_idx, state_dict in enumerate(best_models, start=1):\n",
    "        fold_model = Model().to(device=device)\n",
    "        fold_model.load_state_dict(state_dict)\n",
    "        fold_model.eval()\n",
    "\n",
    "        fold_results = []\n",
    "        for model_inputs in tqdm(test_loader, desc=f\"Fold {fold_idx} [Test]\"):\n",
    "            model_inputs = model_inputs.to(device=device)\n",
    "            fold_results.append(\n",
    "                fold_model(model_inputs)\n",
    "                .cpu().numpy()\n",
    "            )\n",
    "\n",
    "        best_model_preds.append(np.concatenate(fold_results, axis=0))\n",
    "\n",
    "best_model_preds = np.stack(best_model_preds, axis=0)\n",
    "results_best_models = best_model_preds.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
